net: "train_net.prototxt"

base_lr: 0.01
lr_policy: "step"       # step down by factor of gamma every "stepsize" iterations
gamma: 0.1
stepsize: 100
max_iter: 400
momentum: 0.9

# display every n iterations - 100 for testing
display: 100

# save a version of the model every "snapshot" iterations
snapshot: 10000

# test information - iter is num batches, interval is how often we test
test_iter: 3
test_interval: 100

# change obvi depending on where you're running
solver_mode: GPU
snapshot_prefix: "model/dannet"
